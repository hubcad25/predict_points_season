{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 148\n",
      "Taille de l'ensemble de test : 2\n",
      "Taille de l'ensemble d'entraînement : 148\n",
      "Taille de l'ensemble de test : 2\n"
     ]
    }
   ],
   "source": [
    "# Exemple de séries temporelles pour plusieurs joueurs\n",
    "with open('time_on_ice_data.json', 'r') as f:\n",
    "    time_on_ice = json.load(f)\n",
    "\n",
    "# Trouver la longueur maximale des séries temporelles pour faire du padding\n",
    "max_length = max([len(player['past']) for player in time_on_ice.values()])\n",
    "\n",
    "# Separer en training/testing\n",
    "\n",
    "# Convertir le dictionnaire time_on_ice en une liste de tuples (clé, valeur)\n",
    "time_on_ice_items = list(time_on_ice.items())\n",
    "\n",
    "# Séparer en ensemble d'entraînement et de test (80% training, 20% testing)\n",
    "train_data, test_data = train_test_split(time_on_ice_items, test_size=0.01, random_state=42)\n",
    "\n",
    "# Reconvertir les ensembles en dictionnaires\n",
    "train_dict = dict(train_data)\n",
    "test_dict = dict(test_data)\n",
    "\n",
    "# Afficher la taille de chaque ensemble\n",
    "print(f\"Taille de l'ensemble d'entraînement : {len(train_dict)}\")\n",
    "print(f\"Taille de l'ensemble de test : {len(test_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 15, 18, 17, 12,  8, 17,  6, 13,  8, 14, 17, 11, 16,  7, 13, 10,  7,  2,  5,\n",
       "        7,  1, 14, 19,  9,  5, 18, 18,  6,  6, 17, 15,  8, 11,  2,  9, 16, 13, 19, 10,\n",
       "       19,  7,  1, 12, 12, 12, 17,  9, 16, 17, 15, 20, 12,  7, 16, 17, 18,  8, 12, 10,\n",
       "        5, 11,  8, 15, 15, 14, 15, 13,  3, 19,  5,  7, 14,  4, 11, 10, 14,  3, 12, 12,\n",
       "       14,  5,  1,  5,  7, 12, 16,  3, 12, 13, 12, 16, 12,  9, 16,  9,  5, 19,  4,  6,\n",
       "       12,  7, 12, 12,  4, 18,  8, 14,  2, 14, 10,  3,  8, 17, 19,  5,  7, 12,  9,  8,\n",
       "       11, 11,  4,  6,  9, 20, 16, 11, 15,  3,  4, 15,  7, 14,  9,  9,  4, 17,  4, 15,\n",
       "       15,  5,  7, 10, 13, 10, 15,  7])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraire les cibles et les variables fixes (âge, grandeur)\n",
    "targets = np.array([player['target'] for player in train_dict.values()])\n",
    "ages = np.array([player['age'] for player in train_dict.values()])\n",
    "heights = np.array([player['height'] for player in train_dict.values()])\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding des séries temporelles pour qu'elles aient toutes la même longueur\n",
    "padded_series = [\n",
    "    [0] * (max_length - len(player['past'])) + player['past']\n",
    "    for player in train_dict.values()\n",
    "]\n",
    "\n",
    "# Transformer les données en matrices (entrée pour le LSTM)\n",
    "X_time_series = np.array(padded_series).reshape(len(train_dict), max_length, 1)\n",
    "X_fixed = np.column_stack((ages, heights))  # Variables fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les dimensions\n",
    "num_players = len(train_dict)  # Nombre de joueurs (3 dans cet exemple)\n",
    "num_fixed_features = X_fixed.shape[1]  # Nombre de variables fixes (2 ici: âge, grandeur)\n",
    "\n",
    "# Définir les entrées pour le modèle LSTM\n",
    "input_time_series = Input(shape=(max_length, 1), name=\"time_series_input\")\n",
    "input_fixed = Input(shape=(num_fixed_features,), name=\"fixed_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM pour les séries temporelles\n",
    "lstm_output = LSTM(units=50, activation='relu')(input_time_series)\n",
    "\n",
    "# Combiner la sortie du LSTM avec les variables fixes\n",
    "combined = Concatenate()([lstm_output, input_fixed])\n",
    "\n",
    "# Ajouter une couche dense pour la prédiction finale\n",
    "output = Dense(1)(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir et compiler le modèle\n",
    "model = Model(inputs=[input_time_series, input_fixed], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
      "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ time_series_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │           \u001b[38;5;34m0\u001b[0m │ -                   │\n",
      "│ (\u001b[38;5;33mInputLayer\u001b[0m)          │                     │             │                     │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │      \u001b[38;5;34m10,400\u001b[0m │ time_series_input[\u001b[38;5;34m…\u001b[0m │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ fixed_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │           \u001b[38;5;34m0\u001b[0m │ -                   │\n",
      "│ (\u001b[38;5;33mInputLayer\u001b[0m)          │                     │             │                     │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ concatenate_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)          │           \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
      "│ (\u001b[38;5;33mConcatenate\u001b[0m)         │                     │             │ fixed_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │          \u001b[38;5;34m53\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
      "└───────────────────────┴─────────────────────┴─────────────┴─────────────────────┘\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m    Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to       \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│ time_series_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │           \u001b[38;5;34m0\u001b[0m │ -                   │\n",
      "│ (\u001b[38;5;33mInputLayer\u001b[0m)          │                     │             │                     │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │      \u001b[38;5;34m10,400\u001b[0m │ time_series_input[\u001b[38;5;34m…\u001b[0m │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ fixed_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)           │           \u001b[38;5;34m0\u001b[0m │ -                   │\n",
      "│ (\u001b[38;5;33mInputLayer\u001b[0m)          │                     │             │                     │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ concatenate_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)          │           \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
      "│ (\u001b[38;5;33mConcatenate\u001b[0m)         │                     │             │ fixed_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
      "├───────────────────────┼─────────────────────┼─────────────┼─────────────────────┤\n",
      "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │          \u001b[38;5;34m53\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
      "└───────────────────────┴─────────────────────┴─────────────┴─────────────────────┘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,453\u001b[0m (40.83 KB)\n",
      "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,453\u001b[0m (40.83 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,453\u001b[0m (40.83 KB)\n",
      "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,453\u001b[0m (40.83 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
      "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
     ]
    }
   ],
   "source": [
    "# Afficher le résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le modèle avec les données\n",
    "model.fit([X_time_series, X_fixed], targets, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17]\n",
      " [17]\n",
      " [11]\n",
      " [11]\n",
      " [ 4]\n",
      " [12]\n",
      " [ 7]\n",
      " [14]\n",
      " [11]\n",
      " [ 7]]\n",
      "Prediction: [10.150367]\n",
      "[[17]\n",
      " [17]\n",
      " [11]\n",
      " [11]\n",
      " [ 4]\n",
      " [12]\n",
      " [ 7]\n",
      " [14]\n",
      " [11]\n",
      " [ 7]]\n",
      "Prediction: [10.150367]\n"
     ]
    }
   ],
   "source": [
    "# Padding des séries temporelles pour qu'elles aient toutes la même longueur\n",
    "padded_series_test = [\n",
    "    [0] * (max_length - len(player['past'])) + player['past']\n",
    "    for player in test_dict.values()\n",
    "]\n",
    "ages = np.array([player['age'] for player in test_dict.values()])\n",
    "heights = np.array([player['height'] for player in test_dict.values()])\n",
    "\n",
    "# Transformer les données en matrices (entrée pour le LSTM)\n",
    "X_time_series_test = np.array(padded_series_test).reshape(len(test_dict), max_length, 1)\n",
    "X_fixed_test = np.column_stack((ages, heights))  # Variables fixes\n",
    "\n",
    "# Faire des prédictions après l'entraînement\n",
    "predictions = model.predict([X_time_series_test, X_fixed_test])\n",
    "print(X_time_series_test[1])\n",
    "print(\"Prediction:\", predictions[1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
